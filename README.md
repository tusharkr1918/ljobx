# LinkedIn Job Extractor (ljobx)

A fast and simple **command-line tool** to scrape LinkedIn job postings without needing to log in.
It uses **LinkedInâ€™s guest APIs**, supports **proxy rotation**, and provides rich filtering, concurrency, and structured JSON output.

---

## ðŸ”§ Features

* âœ… Search LinkedIn jobs without authentication
* âœ… Filter by **date posted, experience level, job type, remote options**
* âœ… Concurrency & randomized delays for faster + safer scraping
* âœ… Save results to **timestamped JSON files** + `latest` symlink
* âœ… Proxy support via **YAML or remote config URLs**

---

## ðŸš€ Installation

Install directly from **PyPI**:

```sh
pip install ljobx
```

---

## âš¡ Usage

Run `ljobx` from the command line:

```sh
ljobx "Senior Python Developer" "Noida, India" \
      --job-type "Full-time" "Contract" \
      --experience-level "Entry level" "Associate" \
      --date-posted "Past week" \
      --remote "Hybrid" \
      --max-jobs 50 \
      --concurrency 2 \
      --delay 3 8 \
      --log-level DEBUG
```

---

## ðŸ“Œ CLI Options

### Required arguments

* `keywords` â†’ Job title or keywords to search for
* `location` â†’ Geographical location to search in

### Filtering options (from LinkedIn API)

* `--date-posted` â†’ `Any time`, `Past month`, `Past week`, `Past day`
* `--experience-level` â†’ `Internship`, `Entry level`, `Associate`, `Mid-Senior level`, `Director`, `Executive`
* `--job-type` â†’ `Full-time`, `Part-time`, `Contract`, `Temporary`, `Volunteer`, `Internship`, `Other`
* `--remote` â†’ `On-site`, `Remote`, `Hybrid`

### Scraper settings

* `--max-jobs` â†’ Maximum number of jobs to scrape (default: 25)
* `--concurrency` â†’ Number of concurrent requests (default: 2)
* `--delay MIN MAX` â†’ Random delay between requests in seconds (default: 3 8)
* `--log-level` â†’ Logging level (`DEBUG`, `INFO`, `WARNING`, `ERROR`, `CRITICAL`)

### Proxy configuration

* `--proxy-config FILE_OR_URL` â†’ Path or URL to a proxy YAML config

Example config (`config.yml`):

```yaml
proxy_providers:
  - name: webshare
    config:
      api_key: "your_api_key_here"
      page_size: 10

validate_proxies: false
```

---

## ðŸ“‚ Output

Results are saved as JSON under the configured output directory:

* **Timestamped file:**

  ```
  senior_python_developer_20250907_232501.json
  ```
* **Latest symlink (or copy if symlinks not supported):**

  ```
  senior_python_developer_latest.json
  ```

---

## ðŸ›  Example with Proxy

```sh
ljobx "Data Scientist" "Noida, Inda" \
      --max-jobs 30 \
      --proxy-config "config.yml"
```

Or use a remote config:

```sh
ljobx "SDE" "United States" \
      --proxy-config "https://path.to/your/config.yml"
```
